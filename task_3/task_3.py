# -*- coding: utf-8 -*-
"""
task_3.py

"""

import os
import argparse
import time
from pathlib import Path
from dataclasses import dataclass

import numpy as np
import pandas as pd
import torch
import torchmetrics
import torchvision.utils as vutils
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torch import nn
from torch.utils.data import DataLoader
from torch.optim import Adam

import pytorch_lightning as pl
from pytorch_lightning.loggers import CSVLogger
from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint

import matplotlib.pyplot as plt

from clearml import Task, Logger
from getpass import getpass


# ===================== CFG ClearML =====================
@dataclass
class CFG:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞.

    –ê—Ç—Ä–∏–±—É—Ç—ã:
        project_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –≤ ClearML.
        experiment_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –≤ ClearML.
        data_dir (Path): –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –¥–∞–Ω–Ω—ã–º–∏ (—Å–∫–∞—á–∏–≤–∞–Ω–∏–µ/—Ö—Ä–∞–Ω–µ–Ω–∏–µ).
        seed (int): –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤.
        batch_size (int): –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏.
        max_epochs (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.
        num_workers (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ (–≤–æ—Ä–∫–µ—Ä–æ–≤) –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
        learning_rate (float): –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞.
        noise_dim (int): –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ —à—É–º–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞.
        debug_samples_epoch (int): –ß–∞—Å—Ç–æ—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
    """
    project_name: str = "GAN Project"
    experiment_name: str = "Lightning CV"
    data_dir: Path = Path("data")
    seed: int = 127
    batch_size: int = 512
    max_epochs: int = 30
    num_workers: int = 16
    learning_rate: float = 1e-5
    noise_dim: int = 100
    debug_samples_epoch: int = 1


# ===================== DataModule =====================
class MNISTDataModule(pl.LightningDataModule):
    """
    DataModule –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö MNIST.

    –≠—Ç–æ—Ç –∫–ª–∞—Å—Å —É–ø—Ä–∞–≤–ª—è–µ—Ç –≤—Å–µ–º–∏ —Å—Ç–∞–¥–∏—è–º–∏ —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏:
    - prepare_data: —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è 1 —Ä–∞–∑ –Ω–∞ –≤—Å–µ—Ö –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö)
    - setup: —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ train/val/test
    - –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ DataLoader'–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç–∞–¥–∏–∏ –æ–±—É—á–µ–Ω–∏—è
    """

    def __init__(self, _cfg: CFG):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DataModule —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è–º–∏.

        Args:
            _cfg (CFG): –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞.
        """
        super().__init__()
        self.cfg = _cfg

        # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π MNIST:
        # 1) –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä
        # 2) –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É [-1, 1], —á—Ç–æ–±—ã —É—Å–∫–æ—Ä–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ GAN
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,))
        ])

        # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Å—Ç–∞–¥–∏—è—Ö
        self.mnist_train = self.mnist_valid = self.mnist_test = None

    def prepare_data(self):
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç MNIST, –µ—Å–ª–∏ –æ–Ω –µ—â—ë –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω.
        –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –∏ –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –ø–∞–º—è—Ç—å.
        """
        datasets.MNIST(root=self.cfg.data_dir, train=True, download=True)
        datasets.MNIST(root=self.cfg.data_dir, train=False, download=True)

    def setup(self, stage=None):
        """
        –†–∞–∑–¥–µ–ª—è–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç MNIST –Ω–∞ train, validation –∏ test –Ω–∞–±–æ—Ä—ã.

        Args:
            stage (str, optional): –°—Ç–∞–¥–∏—è, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–π –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö.
                                   –ú–æ–∂–µ—Ç –±—ã—Ç—å 'fit', 'validate', 'test' –∏–ª–∏ None.
        """
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        if stage == "fit" or stage is None:
            self.mnist_train = datasets.MNIST(
                root=self.cfg.data_dir,
                train=True,
                transform=self.transform
            )

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å—å —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ
            self.mnist_valid = datasets.MNIST(
                root=self.cfg.data_dir,
                train=False,
                transform=self.transform
            )

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∞
        if stage == "test":
            self.mnist_test = datasets.MNIST(
                root=self.cfg.data_dir,
                train=False,
                transform=self.transform
            )

    def train_dataloader(self):
        """
        –°–æ–∑–¥–∞—ë—Ç DataLoader –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞.

        Returns:
            DataLoader: DataLoader –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.
        """
        return DataLoader(
            self.mnist_train,
            batch_size=self.cfg.batch_size,
            num_workers=self.cfg.num_workers,
            shuffle=False,  # –û–±—ã—á–Ω–æ shuffle=True –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –º–æ–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å
            persistent_workers=True
        )

    def val_dataloader(self):
        """
        –°–æ–∑–¥–∞—ë—Ç DataLoader –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞.

        Returns:
            DataLoader: DataLoader –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏.
        """
        return DataLoader(
            self.mnist_valid,
            batch_size=self.cfg.batch_size,
            num_workers=self.cfg.num_workers,
            shuffle=False,
            persistent_workers=True
        )

    def test_dataloader(self):
        """
        –°–æ–∑–¥–∞—ë—Ç DataLoader –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞.

        Returns:
            DataLoader: DataLoader –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏.
        """
        return DataLoader(
            self.mnist_test,
            batch_size=self.cfg.batch_size,
            num_workers=self.cfg.num_workers,
            shuffle=False,
            persistent_workers=True
        )


# ===================== Model =====================
class Generator(nn.Module):
    def __init__(self, noise_dim):
        super(Generator, self).__init__()
        self.noise_dim = noise_dim
        self.main = nn.Sequential(
            nn.Linear(noise_dim, 256 * 7 * 7),
            nn.ReLU(True),
            nn.Unflatten(1, (256, 7, 7)),
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),
            # -> (128, 14, 14)
            nn.BatchNorm2d(128),
            nn.ReLU(True),
            nn.ConvTranspose2d(128, 1, kernel_size=4, stride=2, padding=1, bias=False),
            # -> (1, 28, 28)
            nn.Tanh()
        )

    def forward(self, x):
        return self.main(x)


class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1, bias=False),
            # -> (64, 14, 14)
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),
            # -> (128, 7, 7)
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Flatten(),
            nn.Linear(128 * 7 * 7, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.main(x)


class GAN(pl.LightningModule):
    """
    GAN-–º–æ–¥–µ–ª—å –Ω–∞ PyTorch Lightning –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π MNIST.

    –°–æ—Å—Ç–æ–∏—Ç –∏–∑ –¥–≤—É—Ö —Å–µ—Ç–µ–π:
        - Generator: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —à—É–º–∞
        - Discriminator: —Ä–∞–∑–ª–∏—á–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

    –ú–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä—É—á–Ω—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é (manual optimization),
    —á—Ç–æ–±—ã –æ—Ç–¥–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è—Ç—å –≤–µ—Å–∞ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞.
    """

    def __init__(self, noise_dim=100, lr=0.0002, betas=(0.5, 0.999), debug_samples_epoch=1):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GAN.

        Args:
            noise_dim (int): –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ —à—É–º–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞.
            lr (float): –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –æ–±–æ–∏—Ö –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤.
            betas (tuple): –ü–∞—Ä–∞–º–µ—Ç—Ä—ã beta1 –∏ beta2 –¥–ª—è Adam (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω—ã –¥–ª—è GAN).
            debug_samples_epoch (int): –ß–∞—Å—Ç–æ—Ç–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏.
        """
        super(GAN, self).__init__()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –≤ Lightning
        self.save_hyperparameters()

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        self.noise_dim = noise_dim
        self.lr = lr
        self.betas = betas
        self.debug_samples_epoch = debug_samples_epoch

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É GAN
        self.generator = Generator(noise_dim)  # –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä
        self.discriminator = Discriminator()  # –î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä

        # –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å ‚Äî –±–∏–Ω–∞—Ä–Ω–∞—è –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è
        self.criterion = nn.BCELoss()

        # –û—Ç–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –≤ Lightning
        self.automatic_optimization = False

        # –õ–æ–≥–≥–µ—Ä –¥–ª—è ClearML
        self.log_clrml = Logger.current_logger()

        # –î–æ–±–∞–≤—å—Ç–µ –º–µ—Ç—Ä–∏–∫–∏
        self.val_f1 = torchmetrics.F1Score(task='multiclass', num_classes=10)
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self.val_f1.reset()

    def forward(self, z):
        """
        –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä.

        Args:
            z (Tensor): –í—Ö–æ–¥–Ω–æ–π —à—É–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ [batch_size, noise_dim].

        Returns:
            Tensor: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
        """
        return self.generator(z)

    def training_step(self, batch, batch_idx):
        """
        –õ–æ–≥–∏–∫–∞ –æ–¥–Ω–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è GAN.
        –í—Ä—É—á–Ω—É—é –æ–±–Ω–æ–≤–ª—è–µ—Ç –≤–µ—Å–∞ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞.

        Args:
            batch (tuple): –ë–∞—Ç—á –¥–∞–Ω–Ω—ã—Ö (—Ä–µ–∞–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –º–µ—Ç–∫–∏).
            batch_idx (int): –ò–Ω–¥–µ–∫—Å –±–∞—Ç—á–∞.

        Returns:
            dict: –°–ª–æ–≤–∞—Ä—å —Å –ø–æ—Ç–µ—Ä—è–º–∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞.
        """
        # –ü–æ–ª—É—á–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã –¥–ª—è –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
        opt_d, opt_g = self.optimizers()

        # –†–∞–∑–¥–µ–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –º–µ—Ç–∫–∏ (–º–µ—Ç–∫–∏ –Ω–µ –Ω—É–∂–Ω—ã)
        real_images, _ = batch
        batch_size = real_images.size(0)
        device = real_images.device

        # –°–æ–∑–¥–∞—ë–º —Ç–µ–Ω–∑–æ—Ä—ã –º–µ—Ç–æ–∫ –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –∏ —Ñ–µ–π–∫–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        real_labels = torch.full((batch_size,), 1.0, device=device)
        fake_labels = torch.full((batch_size,), 0.0, device=device)

        # ================== –®–∞–≥ 1: –æ–±—É—á–µ–Ω–∏–µ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ ==================
        opt_d.zero_grad()

        # 1.1. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        output_real = self.discriminator(real_images).view(-1)
        loss_real = self.criterion(output_real, real_labels)

        # 1.2. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Ñ–µ–π–∫–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        noise = torch.randn(batch_size, self.noise_dim, device=device)
        fake_images = self.generator(noise)
        output_fake = self.discriminator(fake_images.detach()).view(-1)
        loss_fake = self.criterion(output_fake, fake_labels)

        # –û–±—â–∞—è –ø–æ—Ç–µ—Ä—è –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞
        loss_D = loss_real + loss_fake

        # –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏
        self.manual_backward(loss_D)
        opt_d.step()

        # ================== –®–∞–≥ 2: –æ–±—É—á–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ ======================
        opt_g.zero_grad()

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π —à—É–º
        noise = torch.randn(batch_size, self.noise_dim, device=device)
        fake_images = self.generator(noise)
        output = self.discriminator(fake_images).view(-1)

        # –ü–æ—Ç–µ—Ä—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ (—Ö–æ—Ç–∏–º, —á—Ç–æ–±—ã –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä —Å—á–∏—Ç–∞–ª —Ñ–µ–π–∫–∏ —Ä–µ–∞–ª—å–Ω—ã–º–∏)
        loss_G = self.criterion(output, real_labels)

        # –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏
        self.manual_backward(loss_G)
        opt_g.step()

        # ================== –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ==================
        self.log('loss_D', loss_D, prog_bar=True, on_epoch=True)
        self.log('loss_G', loss_G, prog_bar=True, on_epoch=True)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ ClearML
        self.log_clrml.report_scalar("Loss", "Discriminator", loss_D.item(),
                                     iteration=self.global_step)
        self.log_clrml.report_scalar("Loss", "Generator", loss_G.item(),
                                     iteration=self.global_step)

        return {"loss_D": loss_D, "loss_G": loss_G}

    def validation_step(self, batch, batch_idx):
        """
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –Ω–∞ –∫–∞–∂–¥–æ–º –±–∞—Ç—á–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞.
        –ó–¥–µ—Å—å –ª–æ–≥–∏—Ä—É—é—Ç—Å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞–∂–¥—ã–µ N —ç–ø–æ—Ö.

        Args:
            batch (tuple): –ë–∞—Ç—á –¥–∞–Ω–Ω—ã—Ö (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞).
            batch_idx (int): –ò–Ω–¥–µ–∫—Å –±–∞—Ç—á–∞.
        """
        # –õ–æ–≥–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã—Ö —ç–ø–æ—Ö–∞—Ö
        if not self.current_epoch % self.hparams.debug_samples_epoch:
            device = self.device

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —à—É–º –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ–∂–¥—É —ç–ø–æ—Ö–∞–º–∏
            fixed_noise = torch.randn(16, self.noise_dim, device=device)
            fake_images = self.generator(fixed_noise)

            # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º –±–∞—Ç—á –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Å–µ—Ç–∫—É
            grid = vutils.make_grid(fake_images, normalize=True)

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PIL-—Ñ–æ—Ä–º–∞—Ç –¥–ª—è ClearML
            pil_img = transforms.ToPILImage()(grid.cpu())

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ ClearML
            self.log_clrml.report_image(
                "Validation Images",
                f"Epoch {self.current_epoch}",
                iteration=self.global_step,
                image=pil_img
            )

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ –¥–ª—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        # –∏, –≤–æ–∑–º–æ–∂–Ω–æ, –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö, –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∑–∞–¥–∞—á–∏
        # –î–ª—è –ø—Ä–∏–º–µ—Ä–∞ –≤–æ–∑—å–º–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ –Ω–∞ —Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        # –ò–ª–∏ –≤—ã –º–æ–∂–µ—Ç–µ –ø—Ä–∏–Ω–∏–º–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –º–µ—Ç–∫–∏ –∏–∑ batch
        real_images, labels = batch  # –µ—Å–ª–∏ –µ—Å—Ç—å –º–µ—Ç–∫–∏ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

        # –†–∞—Å—á–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        outputs = self.discriminator(real_images).view(-1)
        # –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ —É –≤–∞—Å –µ—Å—Ç—å –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        # –∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –º–æ–∂–Ω–æ –≤—ã—á–∏—Å–ª–∏—Ç—å –º–µ—Ç—Ä–∏–∫—É
        # –∏–Ω–∞—á–µ, –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –º–µ—Ç—Ä–∏–∫—É –∫–∞–∫ –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `labels`
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –≤–æ–∑—å–º–µ–º –º–µ—Ç–∫–∏ –∏–∑ batch

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        self.val_f1.update(outputs, labels)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–∫—Ç–∏–≤–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è Lightning (—á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –æ—à–∏–±–æ–∫)
        self.log("valid_none", 0, prog_bar=False)

    def on_validation_epoch_end(self):
        """
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –±–∞—Ç—á–µ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏.
        –ó–¥–µ—Å—å –≤—ã—á–∏—Å–ª—è–µ–º –∏ –ª–æ–≥–∏—Ä—É–µ–º F1 –∑–∞ —ç–ø–æ—Ö—É.
        """
        f1_value = self.val_f1.compute()
        self.log("valid_f1", f1_value, prog_bar=True, sync_dist=True)
        self.val_f1.reset()

    def configure_optimizers(self):
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞.

        Returns:
            tuple: –°–ø–∏—Å–æ–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤ –∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–æ–≤.
        """
        optimizerD = Adam(self.discriminator.parameters(), lr=self.lr, betas=self.betas)
        optimizerG = Adam(self.generator.parameters(), lr=self.lr, betas=self.betas)
        return [optimizerD, optimizerG], []


# ===================== Training =====================
def run_training(cfg: CFG, datamodule: MNISTDataModule):
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏:

    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        cfg: –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        datamodule: —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∞—Å—Å–∞ MNISTDataModule
    """

    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —É–º–Ω–æ–∂–µ–Ω–∏–π –º–∞—Ç—Ä–∏—Ü (PyTorch 2.0+)
    try:
        torch.set_float32_matmul_precision('high')
    except:
        pass

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    model = GAN(noise_dim=cfg.noise_dim,
                lr=cfg.learning_rate,
                debug_samples_epoch=cfg.debug_samples_epoch
                )

    # –õ–æ–≥–≥–µ—Ä Lightning (—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ CSV)
    csv_logger = CSVLogger("lightning_logs", name="GAN_experiment")

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    accelerator = "gpu" if torch.cuda.is_available() else "cpu"

    # ===================== –û—Å–Ω–æ–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ =====================
    # —á–µ–∫–ø–æ–∏–Ω—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    checkpoint_callback = ModelCheckpoint(
        dirpath=MODEL_DIR,
        filename="best_gan",
        save_top_k=1,
        monitor="loss_D",  # –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è —Ä–∞–Ω–Ω–µ–≥–æ —Å—Ç–æ–ø–∞
        mode="min",  # –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫—É
        save_weights_only=True  # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞
    )

    # —Ä–∞–Ω–Ω–∏–π —Å—Ç–æ–ø
    early_stopping_callback = EarlyStopping(
        patience=5,  # –µ—Å–ª–∏ –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è X —ç–ø–æ—Ö –ø–æ–¥—Ä—è–¥ ‚Äî –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
        monitor="loss_D",
        mode="min",
        verbose=True
    )

    trainer = pl.Trainer(max_epochs=cfg.max_epochs,
                         accelerator=accelerator,
                         logger=csv_logger,
                         deterministic=True,
                         # –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–±—ç–∫–∏
                         callbacks=[checkpoint_callback, early_stopping_callback]
                         )

    start = time.time()
    trainer.fit(model, datamodule)
    print(f"–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {time.time() - start:.1f} —Å–µ–∫—É–Ω–¥")

    # ===================== –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫—Ä–∏–≤—ã—Ö –æ–±—É—á–µ–Ω–∏—è =====================
    metrics = pd.read_csv(csv_logger.log_dir + "/metrics.csv")

    plt.figure(figsize=(12, 5))

    # Loss curves
    # plt.subplot(1, 2, 1)
    plt.plot(metrics["loss_G_epoch"].dropna(), label="loss_G")
    plt.plot(metrics["loss_D_epoch"].dropna(), label="loss_D")
    plt.legend()
    plt.title("Loss")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
    fig_path = MODEL_DIR / "training_curves.png"
    plt.savefig(fig_path)
    plt.close()

    # ===================== –û—Ç–ø—Ä–∞–≤–∫–∞ –≥—Ä–∞—Ñ–∏–∫–∞ –≤ ClearML =====================
    logger = Logger.current_logger()
    logger.report_image(
        title="Learning Curves",
        series="loss",
        local_path=str(fig_path),
    )


# ===================== Main =====================
def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--lr", type=float, help="–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞")
    parser.add_argument("--epoch", type=int, default=10, help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è")
    parser.add_argument("--debug_samples_epoch", type=int, default=1,
                        help="–ß–∞—Å—Ç–æ—Ç–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (1 - –∫–∞–∂–¥—É—é —ç–ø–æ—Ö—É, 2 - –∫–∞–∂–¥—É—é –≤—Ç–æ—Ä—É—é –∏ ...)")
    return parser.parse_args()


def check_clearml_env():
    """
    –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è clearml
    :return:
    """
    required_env_vars = [
        "CLEARML_WEB_HOST",
        "CLEARML_API_HOST",
        "CLEARML_FILES_HOST",
        "CLEARML_API_ACCESS_KEY",
        "CLEARML_API_SECRET_KEY"
    ]

    env_vars = dict(CLEARML_WEB_HOST="https://app.clear.ml/",
                    CLEARML_API_HOST="https://api.clear.ml",
                    CLEARML_FILES_HOST="https://files.clear.ml"
                    )

    def load_env_file(file_path):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞"""
        try:
            if not os.path.exists(file_path):
                return False

            print(f"üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞: {file_path}")
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                    if not line or line.startswith('#') or '=' not in line:
                        continue

                    # –†–∞–∑–¥–µ–ª—è–µ–º –∫–ª—é—á –∏ –∑–Ω–∞—á–µ–Ω–∏–µ
                    key, value = line.split('=', 1)
                    key = key.strip()
                    value = value.strip()

                    # –£–¥–∞–ª—è–µ–º –∫–∞–≤—ã—á–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                    if (value.startswith('"') and value.endswith('"')) or \
                            (value.startswith("'") and value.endswith("'")):
                        value = value[1:-1]

                    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é, –µ—Å–ª–∏ –æ–Ω–∞ –Ω—É–∂–Ω–∞ –∏ –µ—â–µ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞
                    if key in required_env_vars and os.getenv(key) is None:
                        os.environ[key] = value
                        print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {key}")

            return True
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return False

    # –®–∞–≥ 1: –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ .env —Ñ–∞–π–ª–æ–≤
    env_files = (".env", os.path.expanduser("~/.clearml.env"))

    env_loaded = False
    for env_file in env_files:
        if load_env_file(env_file):
            env_loaded = True
            # –ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Å–µ –ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
            missing_after_load = [var for var in required_env_vars if os.getenv(var) is None]
            if not missing_after_load:
                break  # –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞

    # –®–∞–≥ 2: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –ø–µ—Ä–≤—ã—Ö —Ç—Ä–µ—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    for var in required_env_vars[:3]:
        if os.getenv(var) is None:
            os.environ[var] = env_vars[var]
            print(f"‚öôÔ∏è  –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è {var}")

    # –®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    missing_vars = [var for var in required_env_vars if os.getenv(var) is None]

    # –®–∞–≥ 4: –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    if missing_vars:
        print("‚ö†Ô∏è  –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—Ä–µ–¥—ã ClearML –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.")
        for var in missing_vars:
            # –î–ª—è —Å–µ–∫—Ä–µ—Ç–Ω—ã—Ö –∫–ª—é—á–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º getpass
            if "SECRET" in var or "KEY" in var:
                os.environ[var] = getpass(f"–í–≤–µ–¥–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è {var}: ")
            else:
                os.environ[var] = input(f"–í–≤–µ–¥–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è {var}: ")
        print("‚úÖ –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ClearML —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.\n")
    else:
        if env_loaded:
            print("‚úÖ –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ClearML –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ .env —Ñ–∞–π–ª–æ–≤.\n")
        else:
            print("‚úÖ –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ClearML —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏.\n")

    # –®–∞–≥ 5: –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    try:
        config_file = Path.home() / ".clearml.env"
        with open(config_file, 'w', encoding='utf-8') as f:
            f.write("# ClearML Configuration\n")
            f.write(f"# Generated on: {__import__('datetime').datetime.now()}\n")
            for var in required_env_vars:
                value = os.getenv(var)
                if value:
                    f.write(f'{var}="{value}"\n')
            f.write('CUBLAS_WORKSPACE_CONFIG=":4096:8"\n')
        print(f"üíæ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {config_file}")
    except Exception as e:
        print(f"üí° –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é: {e}")

    # –®–∞–≥ 6: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º CUBLAS –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    os.environ["CUBLAS_WORKSPACE_CONFIG"] = ":4096:8"

    # –®–∞–≥ 7: –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é (–±–µ–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤)
    print("\nüìã –ò—Ç–æ–≥–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ClearML:")
    for var in required_env_vars:
        value = os.getenv(var)
        if value:
            if "SECRET" in var or "KEY" in var:
                masked_value = value[:4] + "****" + value[-4:] if len(value) > 8 else "****"
                print(f"  {var}: {masked_value}")
            else:
                print(f"  {var}: {value}")
    print(f"  CUBLAS_WORKSPACE_CONFIG: {os.getenv('CUBLAS_WORKSPACE_CONFIG')}")


# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–≤–æ–¥–∞
def verify_clearml_env():
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é ClearML –±–µ–∑ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–≤–æ–¥–∞
    """
    required_env_vars = [
        "CLEARML_WEB_HOST",
        "CLEARML_API_HOST",
        "CLEARML_FILES_HOST",
        "CLEARML_API_ACCESS_KEY",
        "CLEARML_API_SECRET_KEY"
    ]

    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ClearML...")
    all_set = True

    for var in required_env_vars:
        value = os.getenv(var)
        if not value:
            print(f"‚ùå {var}: –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
            all_set = False
        else:
            if "SECRET" in var or "KEY" in var:
                masked_value = value[:4] + "****" + value[-4:] if len(value) > 8 else "****"
                print(f"‚úÖ {var}: {masked_value}")
            else:
                print(f"‚úÖ {var}: {value}")

    if all_set:
        print("üéâ –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ClearML –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã!")
        return True
    else:
        print("üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ check_clearml_env() –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö")
        return False


if __name__ == "__main__":

    MODEL_DIR = Path("models")
    MODEL_DIR.mkdir(parents=True, exist_ok=True)

    args = parse_args()  # –ø–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã

    check_clearml_env()  # —á–∏—Ç–∞–µ–º/—É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—Ä–µ–¥—ã –¥–ª—è clearml

    # ===================== Init ClearML =====================
    cml_cfg = CFG()

    if args.epoch:
        cml_cfg.max_epochs = args.epoch
    if args.debug_samples_epoch:
        cml_cfg.debug_samples_epoch = args.debug_samples_epoch

    save_cfg = cml_cfg.__dict__.copy()
    save_cfg['data_dir'] = str(save_cfg['data_dir'])

    # —Å–æ–∑–¥–∞—ë–º Task (–≤–∞–∂–Ω–æ, —á—Ç–æ–±—ã –æ–Ω –±—ã–ª –≤–∏–¥–µ–Ω –≥–ª–æ–±–∞–ª—å–Ω–æ)
    task = Task.init(project_name=cml_cfg.project_name,
                     task_name=cml_cfg.experiment_name,
                     task_type=Task.TaskTypes.training)
    task.add_tags(["PyTorch-Lightning", "CV", "GAN"])
    task.connect(save_cfg)
    logger_clearml = Logger.current_logger()

    mnist_dm = MNISTDataModule(cml_cfg)  # –≥–æ—Ç–æ–≤–∏–º –¥–∞—Ç–∞—Å–µ—Ç—ã
    mnist_dm.prepare_data()
    mnist_dm.setup()

    run_training(cml_cfg, mnist_dm)  # –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å

    print("‚úÖ –ó–∞–≤–µ—Ä—à–∞—é Task'—É...")
    task.close()
