import os
import sys
import time
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import argparse

import warnings

import torch
import torch.nn.functional as F
import torchmetrics as tm
import pytorch_lightning as pl
import torchvision.transforms as transforms
from torch import nn
from torchvision.transforms.functional import to_tensor
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
from pathlib import Path
from dataclasses import dataclass
from sklearn.model_selection import train_test_split
from PIL import Image
from pytorch_lightning.loggers import CSVLogger
from pytorch_lightning.callbacks import (EarlyStopping, ModelCheckpoint,
                                         DeviceStatsMonitor, OnExceptionCheckpoint,
                                         )

from transformers import ViTImageProcessor, ViTModel

from getpass import getpass
from clearml import Task, Logger

from set_all_seeds import set_all_seeds
from print_time import print_time, print_msg

# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Agg –±—ç–∫–µ–Ω–¥ - —Ä–∞–±–æ—Ç–∞–µ—Ç –≤–µ–∑–¥–µ
matplotlib.use('Agg')

warnings.filterwarnings('ignore',
                        category=UserWarning,
                        message=".*Producer process has been terminated.*")

SEED = 127

# reproducibility
set_all_seeds(seed=SEED)


def check_clearml_env():
    """
    –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è clearml
    :return:
    """
    required_env_vars = [
        "CLEARML_WEB_HOST",
        "CLEARML_API_HOST",
        "CLEARML_FILES_HOST",
        "CLEARML_API_ACCESS_KEY",
        "CLEARML_API_SECRET_KEY"
    ]

    env_vars = dict(CLEARML_WEB_HOST="https://app.clear.ml/",
                    CLEARML_API_HOST="https://api.clear.ml",
                    CLEARML_FILES_HOST="https://files.clear.ml"
                    )

    def load_env_file(file_path):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞"""
        try:
            if not os.path.exists(file_path):
                return False

            print(f"üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞: {file_path}")
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                    if not line or line.startswith('#') or '=' not in line:
                        continue

                    # –†–∞–∑–¥–µ–ª—è–µ–º –∫–ª—é—á –∏ –∑–Ω–∞—á–µ–Ω–∏–µ
                    key, value = line.split('=', 1)
                    key = key.strip()
                    value = value.strip()

                    # –£–¥–∞–ª—è–µ–º –∫–∞–≤—ã—á–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                    if (value.startswith('"') and value.endswith('"')) or \
                            (value.startswith("'") and value.endswith("'")):
                        value = value[1:-1]

                    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é, –µ—Å–ª–∏ –æ–Ω–∞ –Ω—É–∂–Ω–∞ –∏ –µ—â–µ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞
                    if key in required_env_vars and os.getenv(key) is None:
                        os.environ[key] = value
                        print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {key}")

            return True
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return False

    # –®–∞–≥ 1: –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ .env —Ñ–∞–π–ª–æ–≤
    env_files = [".env", os.path.expanduser("~/.clearml.env"), "clearml.env"]

    env_loaded = False
    for env_file in env_files:
        if load_env_file(env_file):
            env_loaded = True
            # –ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Å–µ –ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
            missing_after_load = [var for var in required_env_vars if os.getenv(var) is None]
            if not missing_after_load:
                break  # –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞

    # –®–∞–≥ 2: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –ø–µ—Ä–≤—ã—Ö —Ç—Ä–µ—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    for var in required_env_vars[:3]:
        if os.getenv(var) is None:
            os.environ[var] = env_vars[var]
            print(f"‚öôÔ∏è  –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è {var}")

    # –®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    missing_vars = [var for var in required_env_vars if os.getenv(var) is None]

    # –®–∞–≥ 4: –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
    if missing_vars:
        print("‚ö†Ô∏è  –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—Ä–µ–¥—ã ClearML –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.")
        for var in missing_vars:
            # –î–ª—è —Å–µ–∫—Ä–µ—Ç–Ω—ã—Ö –∫–ª—é—á–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º getpass
            if "SECRET" in var or "KEY" in var:
                os.environ[var] = getpass(f"–í–≤–µ–¥–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è {var}: ")
            else:
                os.environ[var] = input(f"–í–≤–µ–¥–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è {var}: ")
        print("‚úÖ –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ClearML —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.\n")
    else:
        if env_loaded:
            print("‚úÖ –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ClearML –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ .env —Ñ–∞–π–ª–æ–≤.\n")
        else:
            print("‚úÖ –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ClearML —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏.\n")

    # –®–∞–≥ 5: –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    try:
        config_file = Path.home() / ".clearml.env"
        with open(config_file, 'w', encoding='utf-8') as f:
            f.write("# ClearML Configuration\n")
            f.write(f"# Generated on: {__import__('datetime').datetime.now()}\n")
            for var in required_env_vars:
                value = os.getenv(var)
                if value:
                    f.write(f'{var}="{value}"\n')
            f.write('CUBLAS_WORKSPACE_CONFIG=":4096:8"\n')
        print(f"üíæ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {config_file}")
    except Exception as e:
        print(f"üí° –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é: {e}")

    # –®–∞–≥ 6: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º CUBLAS –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    os.environ["CUBLAS_WORKSPACE_CONFIG"] = ":4096:8"

    # –®–∞–≥ 7: –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é (–±–µ–∑ —Å–µ–∫—Ä–µ—Ç–æ–≤)
    print("\nüìã –ò—Ç–æ–≥–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ClearML:")
    for var in required_env_vars:
        value = os.getenv(var)
        if value:
            if "SECRET" in var or "KEY" in var:
                masked_value = value[:4] + "****" + value[-4:] if len(value) > 8 else "****"
                print(f"  {var}: {masked_value}")
            else:
                print(f"  {var}: {value}")
    print(f"  CUBLAS_WORKSPACE_CONFIG: {os.getenv('CUBLAS_WORKSPACE_CONFIG')}")


# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–≤–æ–¥–∞
def verify_clearml_env():
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é ClearML –±–µ–∑ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –≤–≤–æ–¥–∞
    """
    required_env_vars = [
        "CLEARML_WEB_HOST",
        "CLEARML_API_HOST",
        "CLEARML_FILES_HOST",
        "CLEARML_API_ACCESS_KEY",
        "CLEARML_API_SECRET_KEY"
    ]

    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ClearML...")
    all_set = True

    for var in required_env_vars:
        value = os.getenv(var)
        if not value:
            print(f"‚ùå {var}: –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
            all_set = False
        else:
            if "SECRET" in var or "KEY" in var:
                masked_value = value[:4] + "****" + value[-4:] if len(value) > 8 else "****"
                print(f"‚úÖ {var}: {masked_value}")
            else:
                print(f"‚úÖ {var}: {value}")

    if all_set:
        print("üéâ –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ClearML –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã!")
        return True
    else:
        print("üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ check_clearml_env() –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö")
        return False


# ===================== CFG ClearML =====================
@dataclass
class CFG:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞.

    –ê—Ç—Ä–∏–±—É—Ç—ã:
        project_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –≤ ClearML.
        experiment_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –≤ ClearML.
        test_size (float): –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ train/val.
        seed (int): –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏.
        batch_size (int): –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏.
        max_epochs (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.
        num_workers (int): –ß–∏—Å–ª–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
        root_dir (Path): –ö–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞.
        data_dir (Path): –ö–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞ —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º CXR8.
        images_dir (Path): –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.
        train_csv (str): –ò–º—è CSV-—Ñ–∞–π–ª–∞ —Å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–æ–π.
        test_csv (str): –ò–º—è CSV-—Ñ–∞–π–ª–∞ —Å —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–æ–π.
        weights_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è/–∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏.
        logs_dir (Path): –ü–∞–ø–∫–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–æ–≥–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, clearML).
    """
    project_name: str = "CT Project"
    experiment_name: str = "Lightning + Torchmetrics"
    model_name: str = "Default"
    seed: int = SEED
    test_size: float = 0.2
    batch_size: int = 512
    max_epochs: int = 20
    num_workers: int = 16
    num_samples: int = None

    root_dir: Path = Path("../")
    data_dir: Path = root_dir / "data"
    logs_dir: Path = root_dir / "reports"
    images_dir: Path = data_dir / "images"
    images_preprocessed: Path = data_dir / "processed"
    train_csv: str = "train_val_dataset.csv"
    test_csv: str = "test_dataset.csv"
    output_csv: str = "inference_results.csv"

    img_size: int = 224
    learning_rate: float = 1e-5

    weights_path: Path = root_dir / "models"

    def __post_init__(self):
        if self.num_workers > self.batch_size:
            self.num_workers = self.batch_size
        # —Å–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–∏
        self.weights_path.mkdir(parents=True, exist_ok=True)
        # —Å–æ–∑–¥–∞—ë–º –ø–æ–¥–ø–∞–ø–∫—É –¥–ª—è –ª–æ–≥–æ–≤
        self.logs_dir.mkdir(parents=True, exist_ok=True)


def parse_args():
    """
    –ü–∞—Ä—Å–∏—Ç –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é.

    Returns:
        CFG: –û–±—ä–µ–∫—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏–∑ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.
    """
    parser = argparse.ArgumentParser(description='script for VIT model')

    # –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    parser.add_argument('--data_dir', type=str,
                        help='–ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –¥–∞–Ω–Ω—ã–º–∏')
    parser.add_argument('--weights_path', type=str,
                        help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è/–∑–∞–≥—Ä—É–∑–∫–∏ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏')
    parser.add_argument('--logs_dir', type=str,
                        help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–æ–≥–æ–≤ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')

    # –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    parser.add_argument('--batch_size', type=int,
                        help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è')
    parser.add_argument('--max_epochs', type=int,
                        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –æ–±—É—á–µ–Ω–∏—è')
    parser.add_argument('--learning_rate', type=float,
                        help='–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è')
    parser.add_argument('--img_size', type=int,
                        help='–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è')
    parser.add_argument('--test_size', type=float,
                        help='–î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è')

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument('--model_name', type=str,
                        help='–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏')
    parser.add_argument('--num_workers', type=int,
                        help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ workers –¥–ª—è DataLoader')
    parser.add_argument('--seed', type=int,
                        help='Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏')

    args = parser.parse_args()

    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–æ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    cfg = CFG()

    # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –µ—Å–ª–∏ –æ–Ω–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã –≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ
    if args.data_dir:
        cfg.data_dir = Path(args.data_dir)
        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–≤–∏—Å–∏–º—ã–µ –ø—É—Ç–∏
        cfg.images_dir = cfg.data_dir / "images"
        cfg.images_preprocessed = cfg.data_dir / "processed"

    if args.weights_path:
        cfg.weights_path = Path(args.weights_path)

    if args.logs_dir:
        cfg.logs_dir = Path(args.logs_dir)

    if args.batch_size:
        cfg.batch_size = args.batch_size

    if args.max_epochs:
        cfg.max_epochs = args.max_epochs

    if args.learning_rate:
        cfg.learning_rate = args.learning_rate

    if args.img_size:
        cfg.img_size = args.img_size

    if args.test_size:
        cfg.test_size = args.test_size

    if args.model_name:
        cfg.model_name = args.model_name

    if args.num_workers:
        cfg.num_workers = args.num_workers

    if args.seed:
        cfg.seed = args.seed

    return cfg


# ===================== Dataset =====================
class CXR8Dataset(torch.utils.data.Dataset):
    """
    –ö–∞—Å—Ç–æ–º–Ω—ã–π Dataset –¥–ª—è CXR8.

    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        df (pd.DataFrame): DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ ["Image Index", "target"].
        images_dir (Path): –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏.

    –ú–µ—Ç–æ–¥—ã:
        __len__: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ.
        __getitem__: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –º–µ—Ç–∫–∞) –ø–æ –∏–Ω–¥–µ–∫—Å—É.
    """

    def __init__(self, df, images_dir, preprocessed_dir=None, transform=None,
                 return_image=False):
        self.df = df
        self.images_dir = Path(images_dir)
        self.preprocessed_dir = preprocessed_dir
        self.transform = transform
        self.return_image = return_image

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        label = int(row["target"])
        img_path = self.images_dir / row["Image Index"]
        image_tensor = None

        if self.return_image:
            if self.transform:
                # print('self.transform:', self.transform)
                processed = self.transform(Image.open(img_path).convert("RGB"),
                                           return_tensors="pt")
                # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ pixel_values –∏ —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω—é—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –±–∞—Ç—á–∞
                image_tensor = processed["pixel_values"].squeeze(0)  # [3, H, W]
                # print('image_tensor.shape:', image_tensor.shape)
                return image_tensor, label

            return Image.open(img_path).convert("RGB"), label

        if self.preprocessed_dir:
            pt_file = self.preprocessed_dir / (img_path.stem + ".pt")
            if pt_file.exists():
                # print(f'–ß–∏—Ç–∞—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ñ–∞–π–ª: {img_path}')
                image_tensor = torch.load(pt_file)

        if image_tensor is None:
            image = Image.open(img_path).convert("L")  # —á/–± ‚Üí 1 –∫–∞–Ω–∞–ª

            if self.transform:
                image_tensor = self.transform(image)
                # –õ–µ–Ω–∏–≤–æ –∫—ç—à–∏—Ä—É–µ–º
                if self.preprocessed_dir is not None:
                    pt_file = self.preprocessed_dir / (img_path.stem + ".pt")
                    torch.save(image_tensor, pt_file)
            else:
                image_tensor = to_tensor(image)  # (1, H, W), float32, [0, 1]

        return image_tensor, label


# ===================== BatchAugmentorGPU =====================
class BatchAugmentorGPU:
    """
    –ü–æ–ª–Ω–æ—Å—Ç—å—é –±–∞—Ç—á–µ–≤—ã–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–∞ GPU:
    - Resize
    - Random horizontal flip
    - Random rotation ¬±10¬∞
    - Random zoom ¬±10%
    - Random shift ¬±10% –ø–æ –∫–∞–∂–¥–æ–π –æ—Å–∏
    - Normalize
    """

    def __init__(self, img_size=None, mean=None, std=None, train=True):
        self.img_size = img_size
        self.train = train
        self.mean = mean
        self.std = std

    def __call__(self, batch: torch.Tensor, device: str = "cuda"):
        """
        batch: Tensor [B, C, H, W]
        device: –∫—É–¥–∞ –∫–∏–¥–∞—Ç—å –±–∞—Ç—á
        """
        batch = batch.to(device)

        if self.img_size is not None:
            # Resize
            batch = F.interpolate(batch, size=(self.img_size, self.img_size),
                                  mode='bilinear', align_corners=False)

        if self.train:
            # --- Random Flip –ø–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª–∏ ---
            flip_mask = torch.rand(batch.size(0), device=device) > 0.5
            batch[flip_mask] = batch[flip_mask].flip(dims=[3])

            # --- Random Rotation ¬±10 –≥—Ä–∞–¥—É—Å–æ–≤ ---
            angles = (torch.rand(batch.size(0), device=device) - 0.5) * 20  # –≥—Ä–∞–¥—É—Å—ã
            angles_rad = angles * torch.pi / 180.0
            batch = self.rotate_batch(batch, angles_rad, device)

            # --- Random Zoom (0.9‚Äì1.1) ---
            scales = 0.9 + 0.2 * torch.rand(batch.size(0), device=device)
            batch = self.zoom_batch(batch, scales, device)

        if self.mean is not None and self.std is not None:
            # Normalize
            batch = (batch - self.mean) / self.std

        return batch.cpu()

    @staticmethod
    def rotate_batch(batch, angles_rad, device):
        B, C, H, W = batch.shape
        theta = torch.zeros(B, 2, 3, device=device)
        theta[:, 0, 0] = torch.cos(angles_rad)
        theta[:, 0, 1] = -torch.sin(angles_rad)
        theta[:, 1, 0] = torch.sin(angles_rad)
        theta[:, 1, 1] = torch.cos(angles_rad)
        grid = F.affine_grid(theta, batch.size(), align_corners=False)
        batch = F.grid_sample(batch, grid, mode='bilinear', padding_mode='border',
                              align_corners=False)
        return batch

    @staticmethod
    def zoom_batch(batch, scales, device):
        B, C, H, W = batch.shape
        theta = torch.zeros(B, 2, 3, device=device)
        theta[:, 0, 0] = scales
        theta[:, 1, 1] = scales
        grid = F.affine_grid(theta, batch.size(), align_corners=False)
        batch = F.grid_sample(batch, grid, mode='bilinear', padding_mode='border',
                              align_corners=False)
        return batch


class CollateFn:
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–∞—Ç—á–∞–º–∏ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
    """

    def __init__(self, augmentor, device: str, train: bool = False):
        self.augmentor = augmentor
        self.device = device
        self.train = train
        # print(f'–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—É–≥–º–µ–Ω—Ç–æ—Ä–∞: train={self.train}')

    def __call__(self, batch):
        imgs, labels = zip(*batch)

        # –°–±–æ—Ä–∫–∞ –±–∞—Ç—á–∞
        if getattr(self.augmentor, "image_processor_type", '') in ('YolosImageProcessor',
                                                                   'DetrImageProcessor',
                                                                   "ViTImageProcessor",
                                                                   ):
            inputs = self.augmentor(images=imgs, return_tensors="pt")
            labels = torch.tensor(labels, dtype=torch.long)
            return inputs, labels

        if getattr(self.augmentor, "image_processor_type", '') in (
                'CustomBitImageProcessor',):

            imgs = torch.stack(imgs)  # [B, C, H, W]
            labels = torch.tensor(labels)

        else:
            # ---- –°–ª—É—á–∞–π: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π augmentor (—Å—Ç–∞—Ä—ã–π –∫–æ–¥) ----
            imgs = torch.stack(imgs)  # [B, C, H, W]
            labels = torch.tensor(labels)
            # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (–µ—Å–ª–∏ augmentor –ø–µ—Ä–µ–¥–∞–Ω)
            if self.augmentor is not None:
                # print(f'–í—ã–∑–æ–≤ –∞—É–≥–º–µ–Ω—Ç–æ—Ä–∞: train={self.train}')
                imgs = self.augmentor(imgs, device=self.device)

            # –î–ª—è 3D-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –¥–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—É—é –æ—Å—å –≥–ª—É–±–∏–Ω—ã
            imgs = imgs.unsqueeze(2)  # [B, C, H, W] -> [B, C, 1, H, W]

        return imgs, labels


# ===================== DataModule =====================
class CXR8DataModule(pl.LightningDataModule):
    def __init__(self, cfg_class, device, transformer=None, processor=None, use_images=False,
                 sample=None, mean=None, std=None, calc_stats=False):
        """
        –î–∞—Ç–∞–º–æ–¥—É–ª—å
        :param cfg_class: –∫–ª–∞—Å—Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        :param device: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        :param transformer: —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞
        :param processor: –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        :param use_images: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –≤–º–µ—Å—Ç–æ —Ç–µ–Ω–∑–æ—Ä–æ–≤
        :param sample: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        :param mean: —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É –∫–∞—Ä—Ç–∏–Ω–æ–∫
        :param std: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É –∫–∞—Ä—Ç–∏–Ω–æ–∫
        :param calc_stats: —Å—á–∏—Ç–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –¥–∞—Ç–∞—Å–µ—Ç—É –∫–∞—Ä—Ç–∏–Ω–æ–∫
        """
        super().__init__()
        self.cfg = cfg_class
        self.calc_stats = calc_stats
        self.sample, self.mean, self.std = sample, mean, std
        self.train_dataset = self.valid_dataset = self.test_dataset = None
        self.train_augmentor = self.valid_augmentor = None
        self.device = device
        self.transformer = transformer
        self.processor = processor  # <- –¥–æ–±–∞–≤–∏–ª–∏
        self.use_images = use_images  # <- –¥–æ–±–∞–≤–∏–ª–∏
        self.dataset_pin_memory = True
        self.class_weights = None  # <-- —Å—é–¥–∞ —Å–æ—Ö—Ä–∞–Ω–∏–º –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤

    def setup(self, stage=None):
        # -------------------- –ó–∞–≥—Ä—É–∂–∞–µ–º CSV --------------------
        df = pd.read_csv(self.cfg.data_dir / self.cfg.train_csv)
        test_df = pd.read_csv(self.cfg.data_dir / self.cfg.test_csv)

        if self.sample is not None:
            df, test_df = train_test_split(df,
                                           train_size=self.sample,
                                           random_state=self.cfg.seed,
                                           stratify=df["target"])
            test_df = test_df.sample(self.sample // 2, random_state=self.cfg.seed)

        train_df, valid_df = train_test_split(df,
                                              test_size=self.cfg.test_size,
                                              random_state=self.cfg.seed,
                                              stratify=df["target"]
                                              )
        if self.sample is None:
            test_df = valid_df.copy()

        # ====== —Å—á–∏—Ç–∞–µ–º –≤–µ—Å–∞ ======
        class_counts_ = train_df["target"].value_counts().sort_index()

        self.class_weights = torch.tensor([class_counts_[0] / class_counts_[1]],
                                          dtype=torch.float32).to(self.device)

        # ====== –º–µ—Ç–∫–∏ ======
        print("Train label counts:\n", class_counts_)
        print("Train label ratio (pos fraction):", train_df["target"].mean())
        print("Class weights:", self.class_weights)

        # -------------------- –ü–æ–¥—Å—á—ë—Ç mean/std --------------------
        if self.calc_stats and (self.mean is None or self.std is None):
            # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏
            img_transform = transforms.Compose([transforms.Resize((cfg.img_size,
                                                                   cfg.img_size)),
                                                transforms.ToTensor(),
                                                ])
            tmp_dataset = CXR8Dataset(train_df, self.cfg.images_dir, transform=img_transform)
            loader = DataLoader(tmp_dataset,
                                batch_size=self.cfg.batch_size,
                                shuffle=False,
                                pin_memory=self.dataset_pin_memory,
                                num_workers=self.cfg.num_workers,
                                persistent_workers=True if self.cfg.num_workers > 0 else False,
                                )
            sum_, sum_sq, nb_samples = 0.0, 0.0, 0
            for imgs, _ in tqdm(loader, desc="Computing dataset mean/std"):
                imgs = imgs.float()
                sum_ += imgs.sum()
                sum_sq += (imgs ** 2).sum()
                nb_samples += imgs.numel()
            self.mean = (sum_ / nb_samples).item()
            self.std = torch.sqrt(sum_sq / nb_samples - self.mean ** 2).item()

        if self.mean is not None and self.std is not None:
            print(f"Dataset mean: {self.mean:.5f}, std: {self.std:.5f}")

        # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏
        image_transform = transforms.Compose([
            transforms.Resize((self.cfg.img_size, self.cfg.img_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.25])  # –¥–ª—è grayscale
        ])

        preprocessed_dir = self.cfg.images_preprocessed

        preprocessed_dir = None  # –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –æ—Ç–∫–ª—é—á–µ–Ω–æ

        if preprocessed_dir is None:
            image_transform = None
            cfg_img_size = self.cfg.img_size
        else:
            cfg_img_size = None

        if self.transformer is not None:
            image_transform = self.transformer

        # -------------------- –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç—ã --------------------
        self.train_dataset = CXR8Dataset(train_df, self.cfg.images_dir,
                                         preprocessed_dir=preprocessed_dir,
                                         transform=image_transform,
                                         return_image=self.use_images,
                                         )
        self.valid_dataset = CXR8Dataset(valid_df, self.cfg.images_dir,
                                         preprocessed_dir=preprocessed_dir,
                                         transform=image_transform,
                                         return_image=self.use_images,
                                         )
        self.test_dataset = CXR8Dataset(test_df, self.cfg.images_dir,
                                        preprocessed_dir=preprocessed_dir,
                                        transform=image_transform,
                                        return_image=self.use_images,
                                        )

        # ---------------------------
        # –°–æ–∑–¥–∞–µ–º –±–∞—Ç—á–µ–≤—ã–π –∞—É–≥–º–µ–Ω—Ç–æ—Ä GPU
        # ---------------------------

        # -------------------- –ê—É–≥–º–µ–Ω—Ç–æ—Ä—ã --------------------
        self.train_augmentor = BatchAugmentorGPU(img_size=cfg_img_size,
                                                 mean=self.mean,
                                                 std=self.std,
                                                 train=True)
        self.valid_augmentor = BatchAugmentorGPU(img_size=cfg_img_size,
                                                 mean=self.mean,
                                                 std=self.std,
                                                 train=False)

        if self.transformer is not None:
            self.train_augmentor = self.valid_augmentor = self.transformer

    # -------------------- DataLoaders --------------------
    def train_dataloader(self):
        return DataLoader(self.train_dataset,
                          batch_size=self.cfg.batch_size,
                          shuffle=True,
                          num_workers=self.cfg.num_workers,
                          pin_memory=self.dataset_pin_memory,
                          persistent_workers=True if self.cfg.num_workers > 0 else False,
                          collate_fn=CollateFn(
                              self.processor if self.processor else self.train_augmentor,
                              self.device, train=True),
                          )

    def val_dataloader(self):
        return DataLoader(self.valid_dataset,
                          batch_size=self.cfg.batch_size,
                          shuffle=False,
                          num_workers=self.cfg.num_workers,
                          pin_memory=self.dataset_pin_memory,
                          persistent_workers=True if self.cfg.num_workers > 0 else False,
                          collate_fn=CollateFn(
                              self.processor if self.processor else self.valid_augmentor,
                              self.device, train=False),
                          )

    def test_dataloader(self):
        return DataLoader(self.test_dataset,
                          batch_size=self.cfg.batch_size,
                          shuffle=False,
                          num_workers=self.cfg.num_workers,
                          pin_memory=False,
                          persistent_workers=True if self.cfg.num_workers > 0 else False,
                          collate_fn=CollateFn(
                              self.processor if self.processor else self.valid_augmentor,
                              self.device, train=False),
                          )


class MedicalNetClassifier(nn.Module):
    """
    –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –∏–∑ –ø–∞–∫–µ—Ç–∞ MedicalNet
    """

    def __init__(self, base_model, num_classes=2):
        super().__init__()

        # –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –≤ DataParallel ‚Äî –¥–æ—Å—Ç–∞—ë–º –æ—Ä–∏–≥–∏–Ω–∞–ª
        if isinstance(base_model, nn.DataParallel):
            base_model = base_model.module

        self.base_model = base_model

        # —É–±–∏—Ä–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–æ–Ω–Ω—ã–π head –∏ –¥–æ–±–∞–≤–ª—è–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é
        self.features = nn.Sequential(
            base_model.conv1,
            base_model.bn1,
            base_model.relu,
            base_model.maxpool,
            base_model.layer1,
            base_model.layer2,
            base_model.layer3,
            base_model.layer4,
        )

        # –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool3d(1),  # (B, C, 1, 1, 1)
            nn.Flatten(),
            nn.Linear(512 * base_model.layer4[0].expansion, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x


class MedicalNetModule(pl.LightningModule):
    """
    LightningModule –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–∑–¥–æ—Ä–æ–≤ / –±–æ–ª–µ–Ω).
    –ú–µ—Ç—Ä–∏–∫–∏:
      - Recall (Sensitivity) ‚Äî –æ—Å–Ω–æ–≤–Ω–∞—è
      - Specificity ‚Äî –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è FP
      - AUC_ROC ‚Äî –æ–±—â–∞—è
      - Accuracy ‚Äî –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è
    """

    def __init__(self, resnet_model, weight=None, learning_rate: float = 1e-4):
        super().__init__()
        self.lr = learning_rate
        self.save_hyperparameters()

        # –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å (MedicalNet ResNet)
        self.model = resnet_model

        self.log_clrml = Logger.current_logger()

        # –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
        # self.criterion = nn.CrossEntropyLoss(weight=weight)
        self.criterion = nn.BCEWithLogitsLoss(pos_weight=weight)

        # --- –ú–µ—Ç—Ä–∏–∫–∏ ---
        # Accuracy
        self.train_acc = tm.Accuracy(task="binary")
        self.valid_acc = tm.Accuracy(task="binary")
        # Recall (Sensitivity)
        self.train_recall = tm.Recall(task="binary")
        self.valid_recall = tm.Recall(task="binary")
        # Specificity
        self.train_spec = tm.Specificity(task="binary")
        self.valid_spec = tm.Specificity(task="binary")
        # AUC_ROC
        self.train_auc = tm.AUROC(task="binary").cpu()
        self.valid_auc = tm.AUROC(task="binary").cpu()
        # F1-score
        self.train_f1 = tm.F1Score(task="binary")
        self.valid_f1 = tm.F1Score(task="binary")

    def forward(self, x):
        """–ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥"""
        return self.model(x)

    def basic_step(self, batch, batch_idx, step: str):
        """
        –û–±—â–∏–π —à–∞–≥ –¥–ª—è train/valid:
          - —Å—á–∏—Ç–∞–µ—Ç loss
          - –æ–±–Ω–æ–≤–ª—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏
          - –ª–æ–≥–∏—Ä—É–µ—Ç –≤ Lightning
        """
        x, y = batch

        # y = y.float()  # üî•

        logits = self(x)
        loss = self.criterion(logits, y.float())

        probs = torch.sigmoid(logits)  # –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ 1
        preds = (probs > 0.5).long()  # –±–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")

            # --- –ú–µ—Ç—Ä–∏–∫–∏ ---
            acc = getattr(self, f"{step}_acc")(preds, y)
            recall = getattr(self, f"{step}_recall")(preds, y)
            spec = getattr(self, f"{step}_spec")(preds, y)
            f1 = getattr(self, f"{step}_f1")(preds, y)
            auc = getattr(self, f"{step}_auc")(probs.cpu(), y.cpu())

        metrics_dict = {f"{step}_loss": loss,
                        f"{step}_acc": acc,
                        f"{step}_recall": recall,
                        f"{step}_spec": spec,
                        f"{step}_f1": f1,
                        f"{step}_auc": auc,
                        }

        self.log_dict(metrics_dict, prog_bar=True, on_step=False, on_epoch=True)
        # self.log_dict(metrics_dict, prog_bar=True)

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ ClearML
        self.log_clrml.report_scalar(f"{step}_loss", "epoch", loss.item(), self.current_epoch)
        self.log_clrml.report_scalar(f"{step}_acc", "epoch", acc, self.current_epoch)
        self.log_clrml.report_scalar(f"{step}_recall", "epoch", recall, self.current_epoch)
        self.log_clrml.report_scalar(f"{step}_spec", "epoch", spec, self.current_epoch)
        self.log_clrml.report_scalar(f"{step}_f1", "epoch", f1, self.current_epoch)
        self.log_clrml.report_scalar(f"{step}_auc", "epoch", auc, self.current_epoch)

        return metrics_dict

    def training_step(self, batch, batch_idx):
        metrics_dict = self.basic_step(batch, batch_idx, "train")
        return metrics_dict["train_loss"]

    def validation_step(self, batch, batch_idx):
        metrics_dict = self.basic_step(batch, batch_idx, "valid")
        return metrics_dict["valid_loss"]

    def configure_optimizers(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä"""
        return torch.optim.Adam(self.parameters(), lr=self.lr)


# ===================== Training =====================
def run_training(cfg: dataclass, datamodule: pl.LightningDataModule, resnet_model,
                 task: Task, logger_clearml: Logger, use_class_weights=False,
                 monitor_metric='valid_f1', monitor_metric_mode='max', fast_dev_run=False,
                 save_last_model=True,
                 ):
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:
      - –∑–∞–≥—Ä—É–∑–∫–∏/—Å–∫–∞—á–∏–≤–∞–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞
      - fast_dev_run (–±—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–≥–æ–Ω)
      - –æ–±—É—á–µ–Ω–∏—è –Ω–∞ GPU/CPU
      - –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –≤ CSVLogger –∏ ClearML
      - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
      - –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –æ–±—É—á–µ–Ω–∏—è –≤ ClearML
      - —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –Ω–∞ –æ–¥–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ

    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        args: –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ (–≤–∫–ª—é—á–∞—è load_dataset –∏ fast_dev_run)
        datamodule: —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∞—Å—Å–∞ CXR8DataModule
    """
    weight = None
    if use_class_weights:
        weight = getattr(datamodule, 'class_weights', None)

    print('weight:', weight)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    model = MedicalNetModule(resnet_model, weight=weight, learning_rate=cfg.learning_rate)

    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —É–º–Ω–æ–∂–µ–Ω–∏–π –º–∞—Ç—Ä–∏—Ü (PyTorch 2.0+)
    try:
        torch.set_float32_matmul_precision('high')
    except:
        pass

    # –õ–æ–≥–≥–µ—Ä Lightning (—Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –≤ CSV)
    csv_logger = CSVLogger(str(cfg.logs_dir), name="experiment")

    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    accelerator = "gpu" if torch.cuda.is_available() else "cpu"

    # ===================== –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–≥–æ–Ω =====================
    if fast_dev_run:
        print("–¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–≥–æ–Ω...")
        trainer = pl.Trainer(accelerator=accelerator, fast_dev_run=True, logger=csv_logger)
        try:
            trainer.fit(model, datamodule)
            print("\n–¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–≥–æ–Ω —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–π–¥–µ–Ω")
        except Exception as e:
            print("\n–¢–µ—Å—Ç–æ–≤—ã–π –ø—Ä–æ–≥–æ–Ω –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π:", e)
            print("‚úÖ –ó–∞–≤–µ—Ä—à–∞—é Task'—É...")
            task.close()
            sys.exit(1)

    # ===================== –û—Å–Ω–æ–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ =====================
    # —á–µ–∫–ø–æ–∏–Ω—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    checkpoint_callback = ModelCheckpoint(
        dirpath=cfg.weights_path,
        filename="best_model",
        save_top_k=1,
        monitor=monitor_metric,  # –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è —Ä–∞–Ω–Ω–µ–≥–æ —Å—Ç–æ–ø–∞
        mode=monitor_metric_mode,  # –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ–º / –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫—É
        # save_weights_only=True,  # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞
    )
    # —Ä–∞–Ω–Ω–∏–π —Å—Ç–æ–ø
    early_stopping_callback = EarlyStopping(
        patience=3,  # –µ—Å–ª–∏ –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è 3 —ç–ø–æ—Ö–∏ –ø–æ–¥—Ä—è–¥ ‚Äî –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
        monitor=monitor_metric,  # –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è —Ä–∞–Ω–Ω–µ–≥–æ —Å—Ç–æ–ø–∞
        mode=monitor_metric_mode,  # –º–∞–∫—Å–∏–º–∏–∑–∏—Ä—É–µ–º / –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫—É
        verbose=True
    )
    # –ª–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —É—Å—Ç—Ä–æ–π—Å—Ç–≤
    device_monitor_callback = DeviceStatsMonitor(cpu_stats=True)
    # —á–µ–∫–ø–æ–∏–Ω—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
    on_exception_callback = OnExceptionCheckpoint(dirpath=cfg.weights_path,
                                                  filename="on_exception",
                                                  )
    trainer = pl.Trainer(max_epochs=cfg.max_epochs,
                         accelerator=accelerator,
                         log_every_n_steps=cfg.batch_size,  # –ö–∞–∫ —á–∞—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
                         check_val_every_n_epoch=1,  # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É valid –∫–∞–∂–¥—É—é —ç–ø–æ—Ö—É
                         logger=csv_logger,
                         deterministic=False,  # ‚ö†Ô∏è –∫–ª—é—á–µ–≤–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
                         # –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–±—ç–∫–∏
                         callbacks=[checkpoint_callback,
                                    early_stopping_callback,
                                    # device_monitor_callback,
                                    on_exception_callback,
                                    ]
                         )

    start = time.time()
    trainer.fit(model, datamodule)
    print(f"–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {time.time() - start:.1f} —Å–µ–∫—É–Ω–¥")

    # ===================== –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤ =====================
    ckpt_path = cfg.weights_path / "model.ckpt"
    if save_last_model:
        try:
            trainer.save_checkpoint(str(ckpt_path))
            print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {ckpt_path}")
        except Exception as err:
            print(f'–ú–æ–¥–µ–ª—å –ù–ï —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞, –æ—à–∏–±–∫–∞: {err}')

    # ===================== –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫—Ä–∏–≤—ã—Ö –æ–±—É—á–µ–Ω–∏—è =====================
    metrics = pd.read_csv(csv_logger.log_dir + "/metrics.csv")
    print('–ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ—á–∏—Ç–∞–Ω—ã.')

    try:
        plt.figure(figsize=(12, 5))
        # Loss curves
        plt.subplot(1, 2, 1)
        plt.plot(metrics["train_loss"].dropna(), label="train_loss")
        plt.plot(metrics["valid_loss"].dropna(), label="valid_loss")
        plt.legend()
        plt.title("Loss")

        # Accuracy curves
        plt.subplot(1, 2, 2)
        plt.plot(metrics["train_f1"].dropna(), label="train_f1")
        plt.plot(metrics["valid_f1"].dropna(), label="valid_f1")
        plt.legend()
        plt.title("F1")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫
        fig_path = cfg.logs_dir / "training_curves.png"
        plt.savefig(fig_path)
        plt.close()

        # ===================== –û—Ç–ø—Ä–∞–≤–∫–∞ –≥—Ä–∞—Ñ–∏–∫–∞ –≤ ClearML =====================
        logger_clearml.report_image(
            title="Learning Curves",
            series="Metrics",
            local_path=str(fig_path),
        )
    except Exception as err:
        print(f'–ì—Ä–∞—Ñ–∏–∫ –Ω–µ –ø–æ—Å—Ç—Ä–æ–∏–ª—Å—è, –æ—à–∏–±–∫–∞: {err}')

    try:
        # ===================== –ò–Ω—Ñ–µ—Ä–µ–Ω—Å –Ω–∞ –æ–¥–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ =====================
        for imgs, labels in datamodule.test_dataloader():
            model.eval()
            model.to(device)
            with torch.no_grad():
                probs = torch.sigmoid(model(imgs.to(device)))  # –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ 1
                preds = (probs > 0.5).long()  # –±–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            print(f"–ü—Ä–∏–º–µ—Ä –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: \ntrue={labels.cpu().tolist()[:13]}, "
                  f"\npred={preds.cpu().tolist()[:13]}"
                  f"\nprobs={probs.cpu().numpy().round(2).tolist()[:13]}")
            break  # –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –±–∞—Ç—á
    except RuntimeError as err:
        print(err)

    return str(ckpt_path)


class ViTBinaryClassifier(nn.Module):
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ vit-xray
    """

    def __init__(self, pretrained_model="itsomk/vit-xray-v1",
                 freeze_backbone=True):
        super().__init__()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º backbone –±–µ–∑ –≥–æ–ª–æ–≤—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.vit = ViTModel.from_pretrained(pretrained_model)

        hidden_dim = self.vit.config.hidden_size  # –æ–±—ã—á–Ω–æ 768 –¥–ª—è base

        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø–æ–≤–µ—Ä—Ö CLS-—Ç–æ–∫–µ–Ω–∞
        self.classifier = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, 1)  # –æ–¥–∏–Ω –ª–æ–≥–∏—Ç –≤–º–µ—Å—Ç–æ 2
        )

        # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º backbone (–µ—Å–ª–∏ —Ö–æ—Ç–∏–º –¥–æ–æ–±—É—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –≥–æ–ª–æ–≤—É)
        if freeze_backbone:
            for param in self.vit.parameters():
                param.requires_grad = False
            # –†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ pooler
            for pool_param in self.vit.pooler.parameters():
                pool_param.requires_grad = True

    def forward(self, inputs):
        # inputs = {"pixel_values": tensor[B, 3, 224, 224]}
        outputs = self.vit(**inputs)
        hidden_states = outputs.last_hidden_state  # (B, num_patches+1, hidden_dim)

        # CLS-—Ç–æ–∫–µ–Ω
        cls_token = hidden_states[:, 0, :]  # (B, hidden_dim)

        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        logits = self.classifier(cls_token)  # (B, 1)
        return logits.squeeze(-1)  # (B,) –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å BCEWithLogitsLoss


if __name__ == '__main__':

    # =============== –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è clearml ==========================
    check_clearml_env()

    # ============== –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ =========================
    cfg = parse_args()
    # –í—ã–≤–æ–¥–∏–º —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    print("üìã –¢–µ–∫—É—â–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    for field_name, field_value in cfg.__dict__.items():
        print(f"  {field_name}: {field_value}")

    # ============== –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç–∞–º–æ–¥—É–ª—è –∏ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä–∞ =========================

    device_ = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print('device:', type(device_), device_)

    cfg_ = CFG()

    cfg_.batch_size = 256
    cfg_.num_workers = 24
    cfg_.test_size = 0.05

    datamodule_time = print_msg('–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞—Ç–∞–º–æ–¥—É–ª—è...')
    datamodule_ = CXR8DataModule(cfg_, 'cpu', calc_stats=True)
    datamodule_.setup()  # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å—á–∏—Ç–∞–µ—Ç mean/std –∏ —Å–æ–∑–¥–∞—ë—Ç –¥–∞—Ç–∞—Å–µ—Ç—ã
    print_time(datamodule_time)

    # Mean/std dataset
    print("Train dataset mean/std:", datamodule_.mean, datamodule_.std)

    check_time = print_msg("–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–¥–Ω–æ–≥–æ –±–∞—Ç—á–∞ train'a...")
    for _imgs, _labels in datamodule_.train_dataloader():
        print("Batch images shape:", _imgs.shape)  # [B, C, H, W]
        print("Batch labels shape:", _labels.shape)  # [B]
        print("dtype:", _imgs.dtype, _labels.dtype)  # torch.float32 / torch.int64
        print("device:", _imgs.device, _labels.device)  # –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å cuda
        print("Batch images min/max:", _imgs.min().item(), _imgs.max().item())
        print("–ü—Ä–∏–º–µ—Ä –º–µ—Ç–æ–∫:", _labels[:10].tolist())  # –ø–µ—Ä–≤—ã–µ 10
        break
    print_time(check_time)
